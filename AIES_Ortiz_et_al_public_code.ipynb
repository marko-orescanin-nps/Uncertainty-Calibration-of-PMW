{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b904c0a",
   "metadata": {},
   "source": [
    "# Uncertainty Calibration of Passive Microwave Brightness Temperatures Predicted by Bayesian Deep Learning Models\n",
    "\n",
    "### Pedro Ortiz<sup>a</sup>, Eleanor Casas<sup>a,*</sup>, Marko Orescanin<sup>a</sup>, Scott W. Powell<sup>a</sup>, Veljko Petkovic<sup>b</sup>, Micky Hall<sup>a</sup>\n",
    "\n",
    "<sup>a</sup> Naval Postgraduate School, Monterey, CA, 93943 USA5\n",
    "\n",
    "<sup>b</sup> ESSIC, CISESS, University of Maryland, College Park, MD 20740 USA\n",
    "\n",
    "\n",
    "## Journal Article Summary:\n",
    "\n",
    "This notebook is a companion to the study [\"Uncertainty Calibration of Passive Microwave Brightness Temperatures Predicted by Bayesian Deep Learning Models\" (Ortiz et al. 2023)]() (note: add DOI link when available), which is published in the journal of [Artificial Intelligence for the Earth Systems (AIES)](https://www.ametsoc.org/index.cfm/ams/publications/journals/artificial-intelligence-for-the-earth-systems/) and has a corresponding poster that was presented at both the [Dec 2022 AGU](https://agu.confex.com/agu/fm22/meetingapp.cgi/Paper/1155040) and [Jan 2023 AMS](https://ams.confex.com/ams/103ANNUAL/meetingapp.cgi/Paper/411304) Annual Meetings by Eleanor Casas. This study sought to use artificial intelligence/machine learning (AI/ML) to produce synthetic, ocean-only full-disk Global Precipitation Mission (GMI) microwave brightness temperatures and uncertainties from GOES-16 Advanced Baseline Imager (ABI) infrared brightness temperatures to \"fill in the gaps\" resulting from GMI's low-Earth orbit, and it had the following research objectives and findings:\n",
    "\n",
    "1. **Quantify errors in predicted synthetic passive microwave brightness temperatures using a deterministic model trained on a dataset of limited size**\n",
    "    1. With a minimal dataset trained on just approximately 10% of the month of Jan. 2020, results indicated that synthetic brightness temperatures at higher GMI frequencies generally have lower mean error than those of lower GMI frequencies, with deterministic models indicating mean absolute error (MAE) as low as 1.72 K for predictions of the highest-frequency GMI channel centered at 183±3 GHz.\n",
    "\n",
    "2. **Ascertain whether predictive skill is sacrificed compared to a determinstic model when using Bayesian Deep Learning to quantify variance (a metric of uncertainty)**\n",
    "    1. This study found that model predictive skill differences between [Deterministic](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D), [Bayesian Monte Carlo (MC) Dropout](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dropout), [Bayesian Reparameterization](https://www.tensorflow.org/probability/api_docs/python/tfp/layers/Convolution2DReparameterization), and [Bayesian Flipout](https://www.tensorflow.org/probability/api_docs/python/tfp/layers/Convolution2DFlipout), models were negligible, thus indicating that for this regression task, model skill is not sacrificed when increasing complexity from only predicting microwave brightness temperature to predicting both brightness temperature and total variance at each pixel. \n",
    "\n",
    "3. **Explore how the choice of Bayesian architecture impacts predictive skill and interpretation by focusing on the calibration of predictive error and uncertainty**\n",
    "    1. While predictive skill between model architectures in terms of error metrics were negligible, this study finds that the \"calibration\" between model-predicted variance and error is different between Bayesian architectures. \"Well-calibrated uncertainty\" is defined as a positive, monotonic relationship between the mean absolute error and percent of predictions retained, which is a very important relationship to have when using predicted uncertainty as a proxy for error in downsteam remote sensing applications. This study finds that the Flipout model architecture has the most robust calibration between error and uncertainty for predictions across all GMI channels. \n",
    "\n",
    "\n",
    "<sup>*</sup> Corresponding notebook author address: eleanor.casas@millersville.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb1af72",
   "metadata": {},
   "source": [
    "## Notebook Objectives:\n",
    "\n",
    "This notebook demonstrates how to:\n",
    "\n",
    "1. Load and use a pre-trained MC Dropout model architecture,\n",
    "2. Generate predictions of synthetic 183±3 GHz microwave brightness temperatures and their corresponding uncertainties, \n",
    "3. Plot the spatial output  as in the first row of Fig. 7 in the manuscript, and \n",
    "4. Plot a sample calibration curve from the output. \n",
    "\n",
    "Before beginning, we suggest that you download the provided model checkpoint and data, and then place the paths to your downloads in the lines that contain the phrase \"#Input Path Here\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59c2113",
   "metadata": {},
   "source": [
    "### 1. Package settings and user specifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e21eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all packages/colab settings\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow_probability as tfp #required for Flipout and Reparameterization models\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import AxesGrid\n",
    "import mpl_toolkits.axes_grid1.axes_size as Size\n",
    "from mpl_toolkits.axes_grid1.axes_divider import HBoxDivider\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "from cartopy.mpl.geoaxes import GeoAxes\n",
    "from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter\n",
    "\n",
    "from sklearn.metrics import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8cfdf77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confirm that settings are adequate\n",
    "#The tensorflow version should be at least version 2.4\n",
    "#GPUs are technically not required to reproduce results, but will greatly speed up predictions\n",
    "\n",
    "print(\"Tensorflow Version: \" + tf.__version__)\n",
    "print(\"GPUs available: \" + str(len(tf.config.list_physical_devices('GPU'))))\n",
    "print(\"CPUs available: \" + str(os.cpu_count()))\n",
    "\n",
    "# grab number of gpus automatically\n",
    "gpus = len(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5418daa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#User specifications of prediction hyperparameters\n",
    "\n",
    "#change batch size in accordance with your computer's memory capacity; \n",
    "#larger batches should process a little faster\n",
    "batch_size=1024\n",
    "\n",
    "#Number of predictions used to compute variance (see note in section 4); \n",
    "#not suggested to go below 30 so that you have a sufficiently large sample size\n",
    "num_predictions=30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810fbea3",
   "metadata": {},
   "source": [
    "### 2. Importing Data\n",
    "\n",
    "The provided data is the pre-colocated ABI/GMI data used to produce Fig. 7 in the manuscript. The important variables in each file are:\n",
    "\n",
    "1. \"patchlo\": 39x39 patches of ABI near-infrared and infrared brightness temperatures centered on the corresponding GMI pixel\n",
    "2. \"gmi_pixels\": GMI pixels (at each GMI frequency) that are collocated with the central pixel of ABI patches\n",
    "3. Additional metadata that are not used for generating predictions but are used for making plots (lat, lon, other unused fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fef1733",
   "metadata": {},
   "outputs": [],
   "source": [
    "#definitions used for making the dataset\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "class Data(object):\n",
    "    def __init__(self, batch_size, epochs, ch_name=\"\"):\n",
    "\n",
    "    def _parse_batch_predictions(self, record_batch):\n",
    "            # Create a description of the features\n",
    "            feature_description = {\n",
    "                'lon': tf.io.FixedLenFeature([], tf.float32),\n",
    "                'lat': tf.io.FixedLenFeature([], tf.float32),\n",
    "                'gmi_pixel': tf.io.FixedLenFeature([], tf.float32),\n",
    "                'abi_patch': tf.io.FixedLenFeature([], tf.string)\n",
    "            }\n",
    "\n",
    "            example = tf.io.parse_single_example(record_batch, feature_description)\n",
    "\n",
    "            #Note: These values are normally stored within tfrecords so that patches of arbitrary (or forgotten) dimensions can be used, but storage limits were limiting\n",
    "            depth = 10\n",
    "            height = 39\n",
    "            width = 39\n",
    "\n",
    "            label = example['gmi_pixel']\n",
    "\n",
    "            features = example['abi_patch']\n",
    "            features = tf.io.parse_tensor(features, out_type=tf.float32)\n",
    "            features = tf.reshape(features, shape=[height, width, depth])\n",
    "\n",
    "            latlo = example['lat']\n",
    "\n",
    "            lonlo = example['lon']\n",
    "\n",
    "            return (features, label, latlo, lonlo)\n",
    "\n",
    "\n",
    "    def make_data(self, pattern, shuffle=True):\n",
    "            files_ds = tf.data.Dataset.list_files(pattern, shuffle=shuffle)\n",
    "            ds = tf.data.TFRecordDataset(files_ds, num_parallel_reads=AUTOTUNE)\n",
    "            ds = ds.map(self._parse_batch_predictions, num_parallel_calls=AUTOTUNE)\n",
    "            ds = ds.batch(batch_size)\n",
    "\n",
    "            return ds.prefetch(buffer_size=AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2371a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use the above functions to make the dataset\n",
    "\n",
    "#Provided data contains sample 39x39 patches from approximately 1440 UTC 01 Feb 2020\n",
    "#Note that you should not specify \"*.tfrecord\" here\n",
    "data_path = '' #Input Path Here\n",
    "\n",
    "data = Data(batch_size, 512, channel_name)\n",
    "test_data = data.make_data(os.path.join(data_path, \"*.tfrecord\"),shuffle=False)\n",
    "print(\"Created all datasets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ea89cc",
   "metadata": {},
   "source": [
    "### 3. Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4ed50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note that you should point to the unzipped folder \"/.../29-15.75/\"\n",
    "model_path = '' #Input Path Here\n",
    "model = load_model(model_path, custom_objects={\"tf\": tf})\n",
    "print(\"Model loaded\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae80e6f9",
   "metadata": {},
   "source": [
    "### 4. Generating predictions from the data\n",
    "\n",
    "#### General note regarding variance predictions:\n",
    "\n",
    "- In Determinisitic models, the same set of input features will always produce the same GMI brightness temperature prediction value, no matter how many predictions the user requests (e.g. there is zero variance of predictions). \n",
    "- In this study's Bayesian probabilistic models (like the example MC Dropout model presented herein), the user specifies a certain number of predictions, and variance is computed over the resulting distribution of predicted brightness temperatures for each pixel. \n",
    "- In ongoing and future work, more complex Bayesian models are being created that will directly learn and predict the variance at each pixel, which will allow for uncertainty decomposition in future studies.\n",
    "    - For those interested, preliminary results of these models have been presented so far at [NeurIPS Climate Change AI 2022](https://www.climatechange.ai/papers/neurips2022/22), [IGARSS 2023 (Ortiz et al.: CS focus)](https://2023.ieeeigarss.org/view_paper.php?PaperNum=1881), and [IGARSS 2023 (Casas et al.: MET/Tropical Cyclone Application focus)](https://2023.ieeeigarss.org/view_paper.php?PaperNum=4460). Stay tuned for additional upcoming AMS/AGU conferences and publications!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da57a2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the results array\n",
    "results = None\n",
    "batches = 1\n",
    "for batch in test_data:\n",
    "    # record the results for a single batch\n",
    "    \n",
    "    #parse the tfrecords for relevant analysis variables\n",
    "    y_true = batch[1].numpy()\n",
    "    lat = batch[2].numpy()\n",
    "    lon = batch[3].numpy()\n",
    "\n",
    "    batch_results = np.column_stack((lat, lon, y_true))\n",
    "\n",
    "    # need to make N predictions (set at beginning of notebook)\n",
    "    for i in range(num_predictions):\n",
    "        prediction = model(batch[0])\n",
    "\n",
    "        if isinstance(prediction, tfp.distributions.Distribution):\n",
    "            batch_results = np.column_stack((batch_results, prediction.mean()))\n",
    "            batch_results = np.column_stack((batch_results, prediction.variance()))\n",
    "        else:\n",
    "            batch_results = np.column_stack((batch_results, prediction))\n",
    "\n",
    "    # add batch results to existing results\n",
    "    if results is None:\n",
    "        results = batch_results\n",
    "    else:\n",
    "        results = np.row_stack((results, batch_results))\n",
    "    print(f\"Batch {batches}: \", batch_results.shape, flush=True)\n",
    "    batches += 1\n",
    "\n",
    "print(f\"All Predictions: \", results.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e16369",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optional Step:\n",
    "#write results as csv files with headers\n",
    "\n",
    "#file_path = #Input Path Here\n",
    "#np.savetxt(file_path, results, delimiter=',', header='lat, lon, label, prediction')\n",
    "#print(f\"Predictions saved to {file_path}\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38eca63",
   "metadata": {},
   "source": [
    "### 5. Creating plots from predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de1f0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#If reading from a .csv file of model output:\n",
    "\n",
    "#results = np.genfromtxt(file_path, comments='#', delimiter=\",\", skip_header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991558a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data fields needed for plots\n",
    "\n",
    "lat = results[:, 0]\n",
    "lon = results[:, 1]\n",
    "label = results[:, 2]\n",
    "mean = np.mean(results[:, 3:], axis=1)\n",
    "variance = np.var(results[:, 3:], axis=1)\n",
    "error = mean - label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad26cb1",
   "metadata": {},
   "source": [
    "#### 5a. Example Spatial Plot (Exactly Equivalent to Top Row of Fig. 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751f718d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#general plot settings\n",
    "marker_size = .1\n",
    "marker_style = \",\"\n",
    "all_fonts_size = 8\n",
    "plt.rcParams.update({'font.size': all_fonts_size,\n",
    "                     'axes.titlesize': all_fonts_size,\n",
    "                     'xtick.labelsize': all_fonts_size,\n",
    "                     'ytick.labelsize': all_fonts_size,\n",
    "                     'figure.dpi': 300})\n",
    "\n",
    "projection = ccrs.PlateCarree()\n",
    "axes_class = (GeoAxes, dict(map_projection=projection))\n",
    "\n",
    "#Specifying Longitude labels/graph bounds\n",
    "x_labels = np.linspace(-105, -15, 7)\n",
    "x_bounds = (-95, -45)\n",
    "\n",
    "#Specifying Latitude labels/graph bounds\n",
    "y_labels = np.linspace(-75, 75, 11)\n",
    "y_bounds = (0, 62.5)\n",
    "\n",
    "lon_formatter = LongitudeFormatter(zero_direction_label=True)\n",
    "lat_formatter = LatitudeFormatter()\n",
    "\n",
    "#Specifying GMI TB min/max for colorbars\n",
    "temp_min = 250\n",
    "temp_max = 280\n",
    "temp_labels = [i for i in range(temp_min, temp_max + 1, 5)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2d69b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting the 4-panel spatial plots as in Fig. 7 \n",
    "\n",
    "fig = plt.figure(figsize=(8.5, 4))\n",
    "grid = AxesGrid(fig, 111,  # as in plt.subplot(111)\n",
    "                nrows_ncols=(1, 4),\n",
    "                axes_pad=(.5, .05),\n",
    "                share_all=False,\n",
    "                cbar_mode=\"each\",\n",
    "                cbar_location=\"right\",\n",
    "                cbar_pad=.05,\n",
    "                axes_class=axes_class,\n",
    "                label_mode='')  # note the empty label_mode\n",
    "\n",
    "#Plotting the observed 183 +/- 3 GHz GMI Brightness Temperatures\n",
    "cmap = mpl.cm.RdYlBu_r\n",
    "bounds = [i for i in np.arange(temp_min, temp_max + 1, 2.5)]\n",
    "norm = mpl.colors.BoundaryNorm(bounds, cmap.N, extend='both')\n",
    "grid[0].set_title(f'a) GMI\\nObservations')\n",
    "scat = grid[0].scatter(lon, lat, c=label, cmap=cmap, norm=norm, marker=marker_style, s=marker_size, linewidths=0) \n",
    "#Note: alteratives to scatter are tricontourf or interpolating predictions to a standard grid and using pcolormesh\n",
    "grid[0].coastlines()\n",
    "gl = grid[0].gridlines(crs=ccrs.PlateCarree(), xlocs=x_labels, ylocs=y_labels, color='gray', alpha=0.5)\n",
    "grid[0].set_rasterized(True)\n",
    "grid[0].set_xticks(x_labels, crs=ccrs.PlateCarree())\n",
    "grid[0].tick_params(axis=\"x\", labelrotation=45)\n",
    "grid[0].xaxis.set_major_formatter(lon_formatter)\n",
    "grid[0].set_yticks(y_labels, crs=ccrs.PlateCarree())\n",
    "grid[0].yaxis.set_major_formatter(lat_formatter)\n",
    "grid.cbar_axes[0].remove()  # remove the first colorbar since it is shared with the next plot\n",
    "grid[0].set_xlim(x_bounds[0], x_bounds[1])\n",
    "grid[0].set_ylim(y_bounds[0], y_bounds[1])\n",
    "\n",
    "#Plotting the model-predicted 183pm3 GHz GMI Brightness Temperatures\n",
    "grid[1].set_title(f'b) Predictions')\n",
    "scat = grid[1].scatter(lon, lat, c=mean, cmap=cmap, norm=norm, marker=marker_style, s=marker_size, linewidths=0)\n",
    "grid[1].coastlines()\n",
    "gl = grid[1].gridlines(crs=ccrs.PlateCarree(), xlocs=x_labels, ylocs=y_labels, color='gray', alpha=0.5)\n",
    "grid[1].set_rasterized(True)\n",
    "grid[1].set_xticks(x_labels, crs=ccrs.PlateCarree())\n",
    "grid[1].tick_params(axis=\"x\", labelrotation=45)\n",
    "grid[1].xaxis.set_major_formatter(lon_formatter)\n",
    "grid.cbar_axes[1].colorbar(scat, format='%d', ticks=temp_labels, label=\"T$^{mw}_b$ [K]\", extend=\"both\")\n",
    "grid[1].set_xlim(x_bounds[0], x_bounds[1])\n",
    "grid[1].set_ylim(y_bounds[0], y_bounds[1])\n",
    "\n",
    "#Plotting the error of predictions (prediction - label)\n",
    "error_max = 5  # 183 +/- 3 GHz\n",
    "cmap = mpl.cm.seismic\n",
    "bounds = [i for i in range(-error_max, error_max + 1)]\n",
    "norm = mpl.colors.BoundaryNorm(bounds, cmap.N, extend='both')\n",
    "grid[2].set_title(r'c) Prediction Error')\n",
    "scat = grid[2].scatter(lon, lat, c=error, cmap=cmap, norm=norm, marker=marker_style, s=marker_size, linewidths=0)\n",
    "grid[2].coastlines()\n",
    "gl = grid[2].gridlines(crs=ccrs.PlateCarree(), xlocs=x_labels, ylocs=y_labels, color='gray', alpha=0.5)\n",
    "grid[2].set_rasterized(True)\n",
    "grid[2].set_xticks(x_labels, crs=ccrs.PlateCarree())\n",
    "grid[2].tick_params(axis=\"x\", labelrotation=45)\n",
    "grid[2].xaxis.set_major_formatter(lon_formatter)\n",
    "grid.cbar_axes[2].colorbar(scat, format='%d', ticks=bounds,  label=\"Error [K]\", extend=\"both\")\n",
    "grid[2].set_xlim(x_bounds[0], x_bounds[1])\n",
    "grid[2].set_ylim(y_bounds[0], y_bounds[1]) \n",
    "\n",
    "#Plotting the variance of predictions\n",
    "variance_max  = 1.5 # 183 +/- 3 GHz\n",
    "cmap = mpl.cm.plasma\n",
    "bounds = [i for i in np.arange(0.0, variance_max + 0.1, .125)]\n",
    "norm = mpl.colors.BoundaryNorm(bounds, cmap.N, extend='max')\n",
    "grid[3].set_title(r'd) Uncertainty')\n",
    "scat = grid[3].scatter(lon, lat, c=np.sqrt(variance), cmap=cmap, norm=norm, marker=marker_style, s=marker_size, linewidths=0)\n",
    "grid[3].coastlines()\n",
    "gl = grid[3].gridlines(crs=ccrs.PlateCarree(), xlocs=x_labels, ylocs=y_labels, color='gray', alpha=0.5)\n",
    "grid[3].set_rasterized(True)\n",
    "grid[3].set_xticks(x_labels, crs=ccrs.PlateCarree())\n",
    "grid[3].tick_params(axis=\"x\", labelrotation=45)\n",
    "grid[3].xaxis.set_major_formatter(lon_formatter)\n",
    "grid.cbar_axes[3].colorbar(scat, format='%.2f', ticks=np.arange(0, variance_max+.01, 0.25),  label=\"Standard Deviation [K]\", extend=\"max\")\n",
    "grid[3].set_xlim(x_bounds[0], x_bounds[1])\n",
    "grid[3].set_ylim(y_bounds[0], y_bounds[1])\n",
    "\n",
    "#Adjust axes to account for the extra space resulting from the shared colorbar between (a) and (b)\n",
    "ax1 = grid[0]\n",
    "ax2 = grid[1]\n",
    "cb = grid.cbar_axes[1]\n",
    "divider = HBoxDivider(\n",
    "    fig, 121,\n",
    "    horizontal=[Size.Fixed(.24), Size.AxesX(ax1), Size.Fixed(.2), Size.AxesX(ax2), Size.Fixed(.05), Size.Fixed(0.08), Size.Fixed(0.07)],\n",
    "    vertical=[Size.Scaled(1), Size.AxesY(ax1), Size.Scaled(1), Size.AxesY(ax2), Size.Scaled(1), Size.Scaled(1), Size.Scaled(1)]\n",
    "    , anchor=\"E\"\n",
    ")\n",
    "grid[0].set_axes_locator(divider.new_locator(1))\n",
    "grid[1].set_axes_locator(divider.new_locator(3))\n",
    "grid.cbar_axes[1].set_axes_locator(divider.new_locator(5))\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f0506c",
   "metadata": {},
   "source": [
    "#### 5b. Example Calibration Curve (Computed over different data than what Fig. 6a shows)\n",
    "\n",
    "This code computes \"calibration\" by starting with computing the mean absolute error (MAE) of 100% of predictions, then omitting the top 1% of highest-uncertainty predictions and recomputing the MAE over the remaining 99% of predictions, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2df213",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Computing the calibration curve\n",
    "\n",
    "scale = 100 #percent\n",
    "xs = []\n",
    "ys = []\n",
    "sd = np.sqrt(variance) #standard deviation\n",
    "for i in range(scale, 0, -1):\n",
    "    mask = sd <= np.quantile(sd, i / float(scale))\n",
    "\n",
    "    mean_mask = mean[mask]\n",
    "    label_mask = label[mask]\n",
    "\n",
    "    MAE = mean_absolute_error(label_mask, mean_mask)\n",
    "    # print(i / float(scale), np.quantile(sd, i / float(scale)), MAE)\n",
    "    xs += [int(100 * (i / float(scale)))]\n",
    "    ys += [MAE]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7f616b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting the calibration curve\n",
    "\n",
    "all_fonts_size = 10\n",
    "plt.figure(figsize=(3, 3), constrained_layout=True)\n",
    "plt.rcParams.update({'font.size': all_fonts_size,\n",
    "                     'axes.titlesize': all_fonts_size,\n",
    "                     'xtick.labelsize': all_fonts_size,\n",
    "                     'ytick.labelsize': all_fonts_size,\n",
    "                     'figure.dpi': 300})\n",
    "\n",
    "#calibration curve\n",
    "plt.plot(xs,ys, c='m',label=r'183$\\pm$3 GHz MC Dropout')\n",
    "\n",
    "#arrow with standard deviation label\n",
    "vert_offset = .125\n",
    "plt.annotate(\n",
    "    f\"SD = {np.quantile(sd, .8):.2f}\",\n",
    "    xy=(80, ys[19]),\n",
    "    arrowprops=dict(facecolor='black', width=1, headwidth=7.5),\n",
    "    textcoords='data',\n",
    "    xytext=(60, ys[19] + vert_offset),\n",
    "    horizontalalignment='right',\n",
    "    verticalalignment='center'\n",
    ")\n",
    "\n",
    "#vertical reference line at 80% of predictions retained\n",
    "plt.axvline(80, color=\"black\", linestyle=\":\")\n",
    "\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "plt.xlim(1, 100)\n",
    "plt.xticks(ticks=[1, 20, 40, 60, 80, 100])\n",
    "\n",
    "plt.yticks(ticks=np.arange(0.5, 2.5, .5))\n",
    "\n",
    "plt.xlabel('Percent of Predictions')\n",
    "plt.ylabel('Mean Absolute Error')\n",
    "plt.title(r'Channel 183$\\pm$3 GHz V')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20709b36",
   "metadata": {},
   "source": [
    "### 6. Conclusions\n",
    "\n",
    "If the code is working correctly, you should see that higher error predictions are associated with higher predicted uncertainty in two ways. In the spatial plot, you should be able to reproduce Fig. 7 (top row) and see that regions with clouds/precipitation are consistently associated with higher error and uncertainty than regions with clear air. In the calibration curve, you should see that the MAE of 100% of model predictions is highest, and the MAE of the 1% of lowest uncertainty predictions is approximately the lowest. The curve should also be mostly monotonically increasing from left to right, and this calibration curve is an example of a fairly well-calibrated model. Again, note that the corresponding journal article figure (Fig. 6a) is computed over January test data from multiple days, whereas the example curve produced here is computed only over the data contained within the spatial plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd6c8ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
